{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "CNN vs SpinalFC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "# Device configuration\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "# Hyper-parameters\r\n",
        "num_epochs = 50\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "torch.manual_seed(1)\r\n",
        "random.seed(1)\r\n",
        "\r\n",
        "Half_width =2048\r\n",
        "layer_width = 256\r\n",
        "\r\n",
        "# Image preprocessing modules\r\n",
        "transform = transforms.Compose([\r\n",
        "    transforms.Pad(4),\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    transforms.RandomCrop(32),\r\n",
        "    transforms.ToTensor()])\r\n",
        "\r\n",
        "# CIFAR-10 dataset\r\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\r\n",
        "                                       download=True, transform=transforms.ToTensor())\r\n",
        "\r\n",
        "# Data loader\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset,\r\n",
        "                                           batch_size=200, \r\n",
        "                                           shuffle=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset,\r\n",
        "                                          batch_size=200, \r\n",
        "                                          shuffle=False)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "metadata": {
        "id": "eePqnF-0CZR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce5669c-99f9-4806-f56c-9df6f6fa4f23"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 100)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "f_lFnarCCe-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 3x3 convolution\n",
        "class SpinalCNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(SpinalCNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.fc_spinal_layer1 = nn.Sequential(\n",
        "            nn.Dropout(p=0.1), nn.Linear(Half_width, layer_width),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.fc_spinal_layer2 = nn.Sequential(\n",
        "            nn.Dropout(p=0.1), nn.Linear(Half_width + layer_width, layer_width),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.fc_spinal_layer3 = nn.Sequential(\n",
        "            nn.Dropout(p=0.1), nn.Linear(Half_width + layer_width, layer_width),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.fc_spinal_layer4 = nn.Sequential(\n",
        "            nn.Dropout(p=0.1), nn.Linear(Half_width + layer_width, layer_width),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(p=0.1), nn.Linear(layer_width*4, 100)            \n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x1 = self.fc_spinal_layer1(x[:, 0:Half_width])\n",
        "        x2 = self.fc_spinal_layer2(torch.cat([ x[:,Half_width:2*Half_width], x1], dim=1))\n",
        "        x3 = self.fc_spinal_layer3(torch.cat([ x[:,0:Half_width], x2], dim=1))\n",
        "        x4 = self.fc_spinal_layer4(torch.cat([ x[:,Half_width:2*Half_width], x3], dim=1))\n",
        "        \n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "OWh3JQa1CiEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):    \n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "curr_lr1 = learning_rate\n",
        "\n",
        "curr_lr2 = learning_rate\n",
        "\n",
        "\n",
        "\n",
        "model1 = CNN().to(device)\n",
        "\n",
        "model2 = SpinalCNN().to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
        "  \n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "best_accuracy1 = 0\n",
        "best_accuracy2 =0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model1(images)\n",
        "        loss1 = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer1.zero_grad()\n",
        "        loss1.backward()\n",
        "        optimizer1.step()\n",
        "        \n",
        "        outputs = model2(images)\n",
        "        loss2 = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        if i == 249:\n",
        "            print (\"Ordinary Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss1.item()))\n",
        "            print (\"Spinal Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss2.item()))\n",
        "\n",
        "\n",
        "        \n",
        "    # Test the model\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    with torch.no_grad():\n",
        "        correct1 = 0\n",
        "        total1 = 0\n",
        "        correct2 = 0\n",
        "        total2 = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            \n",
        "            outputs = model1(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total1 += labels.size(0)\n",
        "            correct1 += (predicted == labels).sum().item()\n",
        "            \n",
        "            outputs = model2(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total2 += labels.size(0)\n",
        "            correct2 += (predicted == labels).sum().item()\n",
        "    \n",
        "        \n",
        "        if best_accuracy1> correct1 / total1:\n",
        "            curr_lr1 = curr_lr1/3\n",
        "            update_lr(optimizer1, curr_lr1)\n",
        "            print('Test Accuracy of NN: {} % '.format(100 * correct1 / total1))\n",
        "        else:\n",
        "            best_accuracy1 = correct1 / total1\n",
        "            print('Test Accuracy of NN: {} % (improvement)'.format(100 * correct1 / total1))\n",
        "            \n",
        "        if best_accuracy2> correct2 / total2:\n",
        "            curr_lr2 = curr_lr2/3\n",
        "            update_lr(optimizer2, curr_lr2)\n",
        "            print('Test Accuracy of SpinalNet: {} % '.format(100 * correct2 / total2))\n",
        "        else:\n",
        "            best_accuracy2 = correct2 / total2\n",
        "            print('Test Accuracy of SpinalNet: {} % (improvement)'.format(100 * correct2 / total2))\n",
        "\n",
        "        \n",
        "            \n",
        "        model1.train()\n",
        "        model2.train()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ordinary Epoch [1/50], Step [250/250] Loss: 3.8286\n",
            "Spinal Epoch [1/50], Step [250/250] Loss: 3.5911\n",
            "Test Accuracy of NN: 12.81 % (improvement)\n",
            "Test Accuracy of SpinalNet: 19.36 % (improvement)\n",
            "Ordinary Epoch [2/50], Step [250/250] Loss: 3.2908\n",
            "Spinal Epoch [2/50], Step [250/250] Loss: 2.8962\n",
            "Test Accuracy of NN: 22.42 % (improvement)\n",
            "Test Accuracy of SpinalNet: 27.49 % (improvement)\n",
            "Ordinary Epoch [3/50], Step [250/250] Loss: 2.9499\n",
            "Spinal Epoch [3/50], Step [250/250] Loss: 2.5434\n",
            "Test Accuracy of NN: 27.93 % (improvement)\n",
            "Test Accuracy of SpinalNet: 35.4 % (improvement)\n",
            "Ordinary Epoch [4/50], Step [250/250] Loss: 2.6420\n",
            "Spinal Epoch [4/50], Step [250/250] Loss: 2.2863\n",
            "Test Accuracy of NN: 32.29 % (improvement)\n",
            "Test Accuracy of SpinalNet: 39.67 % (improvement)\n",
            "Ordinary Epoch [5/50], Step [250/250] Loss: 2.5321\n",
            "Spinal Epoch [5/50], Step [250/250] Loss: 2.3668\n",
            "Test Accuracy of NN: 37.14 % (improvement)\n",
            "Test Accuracy of SpinalNet: 42.47 % (improvement)\n",
            "Ordinary Epoch [6/50], Step [250/250] Loss: 2.3940\n",
            "Spinal Epoch [6/50], Step [250/250] Loss: 2.0371\n",
            "Test Accuracy of NN: 39.61 % (improvement)\n",
            "Test Accuracy of SpinalNet: 47.38 % (improvement)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBi3gkJyCPmX",
        "outputId": "ecbd44bc-42cb-421c-f62b-f404874319bf"
      }
    }
  ]
}